{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import requests\n",
    "import lxml\n",
    "from lxml.html.soupparser import fromstring\n",
    "import prettify\n",
    "import numbers\n",
    "import htmltext\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up dataframes & lists for indexing\n",
    "info_cols = ['link','address','beds','baths','sqft']\n",
    "history_cols = ['address','Date','Event','Price']\n",
    "\n",
    "history_df = pd.DataFrame(columns = history_cols)\n",
    "info_df = pd.DataFrame(columns = info_cols)\n",
    "\n",
    "props = ['og:zillow_fb:address','zillow_fb:beds','zillow_fb:baths']\n",
    "labels = ['address','beds','baths','sqft','link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of houses\n",
    "houses = list(pd.read_csv('/Users/lelee1/Desktop/D590TS/homes.csv')['link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in houses:\n",
    "    browser = webdriver.Chrome(executable_path='/Users/lelee1/Desktop/D590TS/chromedriver')\n",
    "    browser.get(url)\n",
    "    soup = BeautifulSoup(browser.page_source)\n",
    "    browser.close()\n",
    "    try:\n",
    "        for x in soup.find_all('meta', {'property':\"og:zillow_fb:address\"},'content'):\n",
    "            address = x.get('content')\n",
    "\n",
    "\n",
    "        concat_events = [tr.get('label') for tr in soup.find_all('tr') if tr.get('label') is not None]\n",
    "\n",
    "        for row in concat_events:\n",
    "            new = []\n",
    "            new_row = row.split(', ')\n",
    "            for x in new_row:\n",
    "                if ':' in x:\n",
    "                    new.append(map(str.strip,x.split(':',1)))\n",
    "            new = dict(new)\n",
    "            new['address'] = address\n",
    "            history_df = history_df.append(new, ignore_index = True)\n",
    "    \n",
    "        info = []\n",
    "        for p in props:\n",
    "            for x in soup.find_all('meta',{'property':p},'content'):\n",
    "                info.append(x.get('content'))\n",
    "        info.append(''.join(re.findall('([0-9])',soup.find_all('span',{'data-testid':\"bed-bath-beyond\"})[0].find_all('span')[6].text)))\n",
    "        info.append(url)\n",
    "        info_new = {labels[i]:info[i] for i in range(len(labels))}\n",
    "        info_df = info_df.append(info_new, ignore_index=True)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes to csv\n",
    "history_df.to_csv('historical_initial.csv')\n",
    "info_df.to_csv('info_initial.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
